{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26d89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2\n",
    "import csv\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import List, Dict\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import lsde2021.csv as csvutils\n",
    "import lsde2021.utils as utils\n",
    "import lsde2021.download as dl\n",
    "import lsde2021.changepoints as cp\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccd66b-83f5-4757-b497-80dace85fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MEMORY = \"30G\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"parse-wikipedia-sql-dumps\") \\\n",
    "    .config(\"spark.executor.memory\", MAX_MEMORY) \\\n",
    "    .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "    .config('spark.driver.maxResultSize', MAX_MEMORY) \\\n",
    "    .config('spark.ui.showConsoleProgress', 'false') \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a818a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wikis = json.loads(\n",
    "    requests.get(\"https://commons.wikimedia.org/w/api.php?action=sitematrix&smtype=language&format=json\").content\n",
    ")\n",
    "pprint(all_wikis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcd91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_dbname(sites):\n",
    "    dnames = [site[\"dbname\"] for site in sites if site[\"code\"] == \"wiki\"]\n",
    "    if len(dnames) > 0:\n",
    "        return dnames[0]\n",
    "    return None\n",
    "\n",
    "wikipedia = {\n",
    "    c[\"code\"]: dict(\n",
    "        # code=c[\"code\"],\n",
    "        name=c[\"localname\"],\n",
    "        dbname=get_wikipedia_dbname(c[\"site\"])\n",
    "    )\n",
    "    for idx, c in all_wikis[\"sitematrix\"].items() if (\n",
    "        idx != \"count\" and get_wikipedia_dbname(c[\"site\"]) is not None\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"total number of languages for wikipedia:\", len(wikipedia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079c3670",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f131a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude languages we dont know, like Lombard or Lingala\n",
    "# also languages that are dead, like Latin\n",
    "# also languages that were never spoken, such as Esperanto\n",
    "\n",
    "selected_language_codes = [\n",
    "    [\"ar\", \"ary\", \"arz\"], # Arabic, Moroccan Arabic, Egyptian Arabic\n",
    "    [\"az\", \"azb\"], # Azerbaijani, South Azerbaijani\n",
    "    [\"bn\"], # Bangla (also Bengali), spoken by 150 million just in Bangladesh\n",
    "    [\"bg\"], # Bulgarian\n",
    "    [\"bs\"], # Bosnian\n",
    "    [\"ca\"], # Catalan\n",
    "    [\"cs\"], # Czech\n",
    "    [\"da\"], # Danish\n",
    "    [\"de\"], # German\n",
    "    [\"el\"], # Greek\n",
    "    [\"en\"], # English\n",
    "    [\"es\"], # Spanish\n",
    "    [\"et\"], # Estonian\n",
    "    [\"fi\"], # Finnish\n",
    "    [\"fr\"], # French\n",
    "    ['fa'], # Persian\n",
    "    [\"ga\"], # Irish\n",
    "    [\"hi\"], # Hindi\n",
    "    [\"he\"], # Hebrew\n",
    "    [\"hu\"], # Hungarian\n",
    "    ['hr', 'sh'], # Croatian, Serbo-Croatian\n",
    "    [\"hy\", \"hyw\"], # Armenian, Western Armenian\n",
    "    [\"id\"], # Indonesian\n",
    "    [\"is\"], # Icelandic\n",
    "    [\"it\"], # Italian\n",
    "    [\"ja\"], # Japanese\n",
    "    [\"ko\"], # Korean\n",
    "    [\"ku\"], # Kurdish\n",
    "    [\"lb\"], # Luxembourgish\n",
    "    [\"lt\"], # Lithuanian\n",
    "    [\"ms\"], # Malay, spoken by 290 million people in Brunei and in malaysia\n",
    "    # [\"my\"], # Burmese, 65% in Myanmar/Burma but only 33 million speakers\n",
    "    [\"nl\"], # Dutch\n",
    "    [\"no\"], # Norwegian\n",
    "    [\"pl\"], # Polish\n",
    "    [\"pt\"], # Portuguese\n",
    "    [\"ro\"], # Romanian\n",
    "    [\"ru\", \"be\", \"bxr\"], # Russian, Belarusian, Russia Buriat\n",
    "    [\"sl\"], # Slovenian\n",
    "    ['sk'], # Slovak\n",
    "    [\"sq\"], # Albanian\n",
    "    [\"sr\"], # Serbian\n",
    "    [\"sv\"], # Swedish\n",
    "    # ['tn'], # Tswana, spoken by 77% in botswana\n",
    "    [\"tr\"], # Turkish\n",
    "    ['th'], # Thai\n",
    "    [\"uk\"], # Ukrainian\n",
    "    [\"vi\"], # Vietnamese\n",
    "    [\"zh\", \"gan\", \"cdo\", \"zh-classical\", \"zh-min-nan\"], # Chinese, Gan Chinese, Min Dong Chinese, Classical Chinese, Chinese (Min Nan)\n",
    "]\n",
    "selected_language_names = [[wikipedia[c][\"name\"] for c in group] for group in selected_language_codes]\n",
    "pprint(selected_language_names)\n",
    "print(\"total number of selected languages for wikipedia: %d (%d)\" % (\n",
    "    sum([len(group) for group in selected_language_codes]), len(selected_language_codes))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3018d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the wikis actually exists\n",
    "wikimedia_dump = \"https://dumps.wikimedia.org/%s/20211001/\"\n",
    "\n",
    "def page_exists(url):\n",
    "    try:\n",
    "        _ = requests.get(url)\n",
    "        return True\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(e)\n",
    "        if e.response.return_code == 404:\n",
    "            return False\n",
    "        raise e\n",
    "\n",
    "existing_language_codes = [\n",
    "    [c for c in group if page_exists(wikimedia_dump % (wikipedia[c][\"dbname\"]))]\n",
    "    for group in selected_language_codes\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd8159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total number of selected languages for wikipedia: %d (%d) of %d\" % (\n",
    "    sum([len(group) for group in existing_language_codes]), len(existing_language_codes), len(wikipedia)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4f08d-c63c-48ca-997a-1001b4ecc943",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_wikipedia = {}\n",
    "for group in existing_language_codes:\n",
    "    for c in group:\n",
    "        selected_wikipedia[c] = {**wikipedia[c], **dict(group=group[0])}\n",
    "df = pd.DataFrame.from_dict(selected_wikipedia, orient='index')\n",
    "df = spark.createDataFrame(df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7592d40-3a7d-4d5c-a290-9880fdd1f1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the ISO3 country names for each language\n",
    "stringency = spark.read.format(\"parquet\").load(f\"../nvme/oxcgrt-covid-policy-tracker/OxCGRT_withnotes.parquet\")\n",
    "stringency = stringency.select(F.col(\"CountryName\").alias(\"country\"), F.col(\"CountryCode\").alias(\"iso3\")).distinct()\n",
    "stringency.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6f2e7-b36c-4b6a-a3f2-7da25ce8d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_countries_handler(s):\n",
    "    return cp.COUNTRIES.get(s, [])\n",
    "country_udf = F.udf(get_countries_handler, T.ArrayType(T.StringType()))\n",
    "\n",
    "df = df.withColumn(\"countries\", country_udf(df['group']))\n",
    "df = df.select(\"name\", \"dbname\", \"group\", F.explode(\"countries\").alias(\"country\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b4bd2e-9221-4fac-9b06-d9426367289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(stringency, on=\"country\", how=\"inner\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1484e08d-df09-484d-9b3d-7c5769fc8e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes_schema = T.StructType([\n",
    "    T.StructField(\"name\", T.StringType(), True),\n",
    "    T.StructField(\"cca2\",T.StringType(), True),\n",
    "    T.StructField(\"cca3\", T.StringType(), True),\n",
    "    T.StructField(\"ccn3\", T.IntegerType(), True),\n",
    "])\n",
    "\n",
    "country_codes = spark.read.format(\"csv\").schema(country_codes_schema).options(header=True).load(\"../nvme/country_codes_2020.csv\")\n",
    "country_codes = country_codes.select(F.col(\"name\"), F.col(\"cca3\").alias(\"iso3\"))\n",
    "\n",
    "population_sizes_schema = T.StructType([\n",
    "    T.StructField(\"Rank\", T.IntegerType(), True),\n",
    "    T.StructField(\"name\",T.StringType(), True),\n",
    "    T.StructField(\"pop2019\", T.FloatType(), True),\n",
    "    T.StructField(\"pop2018\", T.FloatType(), True),\n",
    "    T.StructField(\"GrowthRate\", T.FloatType(), True),\n",
    "    T.StructField(\"area\", T.IntegerType(), True),\n",
    "    T.StructField(\"Density\", T.FloatType(), True),\n",
    "])\n",
    "\n",
    "population_sizes = spark.read.format(\"csv\").schema(population_sizes_schema).options(header=True).load(\"../nvme/countries_by_population_2019.csv\")\n",
    "population_sizes = population_sizes.select(F.col(\"name\"), F.col(\"pop2019\").alias(\"population_size\"))\n",
    "population_sizes = population_sizes.join(country_codes, on=\"name\", how=\"inner\")\n",
    "population_sizes = population_sizes.select(F.col(\"iso3\"), F.col(\"population_size\"))\n",
    "population_sizes = population_sizes.withColumn(\"population_size\", (1_000 * population_sizes[\"population_size\"]).cast(T.IntegerType()))\n",
    "population_sizes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b701e-ba39-4a7d-be93-5a2bf6ae6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(population_sizes, on=\"iso3\", how=\"left\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea830dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the list of languages we will use\n",
    "df.write.format(\"parquet\").mode(\"overwrite\").save(\"./data/languages.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48dbf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"./website/src/data\")\n",
    "languages_countries_out_path = out_path / \"languages_countries.json\"\n",
    "languages_countries_out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "languages_json = [json.loads(s) for s in df.toJSON().collect()]\n",
    "pprint(languages_json[:2])\n",
    "\n",
    "with open(languages_countries_out_path, \"w\") as f:\n",
    "    json.dump(languages_json, f, indent=2, sort_keys=True, default=str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
