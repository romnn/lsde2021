{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2743fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import bz2\n",
    "import csv\n",
    "import io\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import lsde2021.csv as csvutil\n",
    "import lsde2021.utils as utils\n",
    "import lsde2021.download as dl\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, IntegerType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293c9a2-89a7-4ea1-8a4b-00c571fab774",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MEMORY = \"60G\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"parse-wikipedia-sql-dumps\") \\\n",
    "    .config(\"spark.executor.memory\", MAX_MEMORY) \\\n",
    "    .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "    .config('spark.driver.maxResultSize', MAX_MEMORY) \\\n",
    "    .config('spark.ui.showConsoleProgress', 'false') \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "csv_loader = spark.read.format(\"csv\").options(header='True', inferSchema='True')\n",
    "parquet_reader = spark.read.format(\"parquet\").options(inferSchema='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a097c72-dadc-4680-b9a2-dd090997bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join categories with english wiki page table\n",
    "wiki = \"enwiki\"\n",
    "raw_pages = parquet_reader.load(f\"../nvme/wikipedia_sql_dumps/{wiki}/20211001/{wiki}-20211001-page.sql.parquet\")\n",
    "raw_categorylinks = parquet_reader.load(f\"../nvme/wikipedia_sql_dumps/{wiki}/20211001/{wiki}-20211001-categorylinks.sql.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebeecd8-b355-49fd-81a6-4fa459674340",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pages.limit(10).show()\n",
    "raw_categorylinks.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b3c21-ea8e-41ed-af93-9133bfc3edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = raw_pages \\\n",
    "    .filter((F.col(\"page_is_redirect\") == 0)) \\\n",
    "    .filter((F.col(\"page_namespace\") == 0) | (F.col(\"page_namespace\") == 14)) \\\n",
    "    .select(\"page_id\", \"page_namespace\", \"page_title\")\n",
    "\n",
    "categorylinks = raw_categorylinks \\\n",
    "    .select(\"page_id\", \"category_name\")\n",
    "\n",
    "category_pages = pages \\\n",
    "    .filter(F.col(\"page_namespace\") == 14) \\\n",
    "    .select(\n",
    "        F.col(\"page_id\").alias(\"category_page_id\"),\n",
    "        F.col(\"page_title\").alias(\"category_name\"),\n",
    "    )\n",
    "\n",
    "print(pages.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0f93cc-b103-4147-a366-ce156db7c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the categories of the page\n",
    "# .limit(100_000) \\\n",
    "page_cats = pages \\\n",
    "    .join(categorylinks, on=\"page_id\", how=\"inner\")\n",
    "\n",
    "# find the page_id for the categories\n",
    "page_cats = page_cats \\\n",
    "    .join(category_pages, on=\"category_name\", how=\"left\")\n",
    "\n",
    "page_cats.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459eac06-09d9-4743-ae9d-dd21133c6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count topic popularity by number of pages\n",
    "duplicate_counts = page_cats \\\n",
    "    .groupby([\"page_id\"]) \\\n",
    "    .count()\n",
    "\n",
    "page_cats = page_cats \\\n",
    "    .join(duplicate_counts, on=\"page_id\", how=\"inner\") \\\n",
    "    .sort('count', ascending=False) \\\n",
    "\n",
    "page_cats.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047520ba-04ba-4e9e-aa7c-70ab79cfc1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the pages with category\n",
    "page_cats.write.format(\"parquet\").mode(\"overwrite\").save(f\"../nvme/wikipedia_sql_dumps/{wiki}/20211001/{wiki}-20211001-page-category-count.sql.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d593d-57c3-4b3c-b3cf-45fad7b886d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "max_size = None # 100_000\n",
    "for i, row in enumerate(page_cats.rdd.toLocalIterator()):\n",
    "    if i % ((max_size or 20_000_000) / 10) == 0:\n",
    "        print(\"row\", i)\n",
    "        \n",
    "    node = row[\"page_id\"]\n",
    "    node_count = row[\"count\"]\n",
    "    \n",
    "    category_node = row[\"category_page_id\"]\n",
    "    is_category = False\n",
    "    try:\n",
    "        is_category = int(row[\"page_namespace\"]) == 14\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    valid_node = node is not None and node is not np.nan\n",
    "    valid_category_node = category_node is not None and category_node is not np.nan\n",
    "    \n",
    "    # add page node\n",
    "    if valid_node:\n",
    "        if node not in graph.nodes:\n",
    "            graph.add_node(node, is_category=is_category, title=row[\"page_title\"], node_count=node_count)\n",
    "        else:\n",
    "            graph.update(nodes={\n",
    "                node: dict(is_category=is_category, title=row[\"page_title\"], node_count=node_count)\n",
    "            })\n",
    "    \n",
    "    # add category node\n",
    "    if valid_category_node and category_node not in graph.nodes:\n",
    "        graph.add_node(category_node, is_category=True, title=row[\"category_name\"], node_count=0)\n",
    "    \n",
    "    # add the edge between them\n",
    "    if valid_node and valid_category_node:\n",
    "        graph.add_edge(node, category_node)\n",
    "    \n",
    "    if max_size is not None and i >= max_size:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4a47b-bacd-48ed-a3de-30466a6d5c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the graph for reuse\n",
    "nx.write_gpickle(graph, f\"../nvme/en-category-tree.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e4924-f8ef-4be2-b67c-f0075e3128d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the graph for reuse\n",
    "# graphml is too slow\n",
    "# nx.write_graphml_lxml(graph, f\"../nvme/en-category-tree.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb9201c-7311-4d0c-84e1-61dc975b36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first have a closer look at some of the categories and how they look like so we can split them eventually\n",
    "example_categories = page_cats.select(\"category_name\").limit(1_000).rdd.flatMap(lambda x: x).collect()\n",
    "pprint(example_categories[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b359c6-0f9d-486f-b567-ad05d302df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = nx.get_node_attributes(graph, 'title')\n",
    "colors = [\"lightblue\" if is_cat else \"orange\" for node, is_cat in nx.get_node_attributes(graph, 'is_category').items()]\n",
    "plt.figure(figsize=(12,12)) \n",
    "pos = nx.spring_layout(graph)\n",
    "_ = nx.draw_networkx_edges(graph, pos, alpha=0.2)\n",
    "_ = nx.draw_networkx_nodes(graph, pos, label=labels, node_size=1000, node_color=colors)\n",
    "_ = nx.draw_networkx_labels(graph, pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
